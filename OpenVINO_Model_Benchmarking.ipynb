{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bbefcf",
   "metadata": {},
   "source": [
    "\n",
    "# OpenVINO Model Benchmarking\n",
    "\n",
    "This notebook benchmarks the performance of a simple and optimized UNet model on both CPU and GPU using OpenVINO. \n",
    "It measures inference time and plots the comparison results.\n",
    "\n",
    "---\n",
    "### Steps:\n",
    "1. Preprocess an input image to match the model requirements.\n",
    "2. Run inference on CPU and GPU for both simple and optimized models.\n",
    "3. Collect metrics (inference time).\n",
    "4. Visualize results using a bar graph.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb35d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from openvino.runtime import Core\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665881f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Paths to OpenVINO model files\n",
    "SIMPLE_MODEL_XML = \"path/to/simple_model.xml\"\n",
    "OPTIMIZED_MODEL_XML = \"path/to/optimized_model.xml\"\n",
    "\n",
    "# Initialize OpenVINO Core\n",
    "ie = Core()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26adeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_image(image_path, target_shape=(480, 368)):\n",
    "    \"\"\"Preprocess input image.\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if image is None:\n",
    "        raise FileNotFoundError(f\"Image not found at {image_path}.\")\n",
    "    _, thresholded = cv2.threshold(image, 10, 255, cv2.THRESH_BINARY)\n",
    "    resized = cv2.resize(thresholded, target_shape)\n",
    "    rgb_image = cv2.cvtColor(resized, cv2.COLOR_GRAY2RGB)\n",
    "    normalized = rgb_image / 255.0\n",
    "    transposed = normalized.transpose(2, 0, 1)\n",
    "    return np.expand_dims(transposed, axis=0).astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef21fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_inference(image_path, model_path, device=\"CPU\"):\n",
    "    \"\"\"Run model inference.\"\"\"\n",
    "    model = ie.read_model(model=model_path)\n",
    "    compiled_model = ie.compile_model(model=model, device_name=device)\n",
    "    input_tensor = preprocess_image(image_path)\n",
    "    \n",
    "    # Measure inference time\n",
    "    start_time = time.time()\n",
    "    results = compiled_model([input_tensor])\n",
    "    inference_time = time.time() - start_time\n",
    "    \n",
    "    output = next(iter(results.values()))\n",
    "    segmentation_mask = np.argmax(output, axis=1).squeeze().astype(np.uint8)\n",
    "    \n",
    "    return inference_time, segmentation_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329bee7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def benchmark_models(image_path):\n",
    "    \"\"\"Benchmark both models on CPU and GPU.\"\"\"\n",
    "    configurations = [\n",
    "        (\"Simple Model\", SIMPLE_MODEL_XML, \"CPU\"),\n",
    "        (\"Simple Model\", SIMPLE_MODEL_XML, \"GPU\"),\n",
    "        (\"Optimized Model\", OPTIMIZED_MODEL_XML, \"CPU\"),\n",
    "        (\"Optimized Model\", OPTIMIZED_MODEL_XML, \"GPU\"),\n",
    "    ]\n",
    "    metrics = []\n",
    "    \n",
    "    for name, model_path, device in configurations:\n",
    "        time_taken, _ = run_inference(image_path, model_path, device=device)\n",
    "        metrics.append((name, device, time_taken))\n",
    "        print(f\"{name} on {device} - Time: {time_taken:.4f}s\")\n",
    "    \n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80833840",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_results(metrics):\n",
    "    \"\"\"Plot benchmark results.\"\"\"\n",
    "    labels = [f\"{name}-{device}\" for name, device, _ in metrics]\n",
    "    times = [time for _, _, time in metrics]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    bars = ax.bar(labels, times, color=[\"blue\", \"skyblue\", \"green\", \"lightgreen\"], alpha=0.7)\n",
    "    \n",
    "    for bar, time in zip(bars, times):\n",
    "        ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.02, f\"{time:.2f}s\", ha='center', fontsize=10)\n",
    "    \n",
    "    ax.set_ylabel(\"Inference Time (s)\")\n",
    "    ax.set_title(\"Inference Time Comparison: Simple vs. Optimized Models on CPU and GPU\")\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00fa05bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example usage:\n",
    "# Provide the path to an image for benchmarking\n",
    "image_path = \"path/to/test_image.jpg\"\n",
    "\n",
    "# Benchmark models and collect metrics\n",
    "metrics = benchmark_models(image_path)\n",
    "\n",
    "# Plot the results\n",
    "plot_results(metrics)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
